{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hugging Face Image Dataset Browser\n",
        "\n",
        "This notebook demonstrates how to load an image dataset from the Hugging Face Hub and visualize samples. The dataset is defined in one place at the top via `DATASET_ID`, currently set to `friedrice231/SG_Memes`.\n",
        "\n",
        "References:\n",
        "- Hugging Face Datasets: Load a dataset from the Hub ([docs](https://huggingface.co/docs/datasets/load_hub))\n",
        "- Dataset: `friedrice231/SG_Memes` ([dataset card](https://huggingface.co/datasets/friedrice231/SG_Memes))\n",
        "\n",
        "> Tip: Use streaming to avoid downloading the entire dataset if you only need to preview samples.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'datasets'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdataclasses\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dataclass\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dataset, get_dataset_split_names, load_dataset_builder\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'datasets'"
          ]
        }
      ],
      "source": [
        "# Optional: install dependencies in the notebook environment\n",
        "# You can skip this if already installed in your env\n",
        "# %pip install -q datasets pillow matplotlib\n",
        "\n",
        "from typing import List, Optional\n",
        "from dataclasses import dataclass\n",
        "\n",
        "import os\n",
        "from datasets import load_dataset, get_dataset_split_names, load_dataset_builder\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# For better inline figure display\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration (single source of truth)\n",
        "DATASET_ID = \"friedrice231/SG_Memes\"  # change this to switch datasets\n",
        "\n",
        "# If set, load a specific split (e.g., \"train\"). If None, the loader will\n",
        "# automatically choose a sensible default (\"train\" if present, else the first split).\n",
        "BROWSE_SPLIT = None\n",
        "\n",
        "# If True, load via streaming to avoid full download; if False, download/cache the full dataset\n",
        "USE_STREAMING = False\n",
        "\n",
        "# Number of samples to show/save in some utilities\n",
        "NUM_SAMPLES_DEFAULT = 4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inspect dataset builder info and available splits\n",
        "builder = load_dataset_builder(DATASET_ID)\n",
        "print(\"Description:\\n\", (builder.info.description or \"\").strip()[:600], \"...\\n\")\n",
        "print(\"Features:\", builder.info.features)\n",
        "\n",
        "try:\n",
        "    splits = get_dataset_split_names(DATASET_ID)\n",
        "    print(\"Available splits:\", splits)\n",
        "except Exception as e:\n",
        "    print(\"Could not list splits:\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load dataset (streaming vs full download)\n",
        "if USE_STREAMING:\n",
        "    ds = load_dataset(DATASET_ID, split=SPLIT, streaming=True)\n",
        "    print(\"Loaded streaming dataset.\")\n",
        "else:\n",
        "    ds = load_dataset(DATASET_ID, split=SPLIT)\n",
        "    print(\"Loaded dataset:\", ds)\n",
        "\n",
        "# Peek first element safely (works for both streaming and non-streaming)\n",
        "first_row = next(iter(ds)) if USE_STREAMING else ds[0]\n",
        "print(\"Columns:\", list(first_row.keys()))\n",
        "print(\"Example filename:\", first_row.get(\"filename\"))\n",
        "print(\"Example image id:\", first_row.get(\"img_id\"))\n",
        "print(\"Number of captions:\", len(first_row.get(\"caption\", [])))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_sample(row: dict, title: Optional[str] = None):\n",
        "    \"\"\"Display a single sample with image and up to 2 captions.\"\"\"\n",
        "    image = row.get(\"image\")\n",
        "    captions = row.get(\"caption\", [])\n",
        "\n",
        "    # Hugging Face Datasets with Image feature typically returns PIL.Image.Image\n",
        "    if isinstance(image, Image.Image):\n",
        "        plt.figure(figsize=(6, 6))\n",
        "        plt.imshow(image)\n",
        "        plt.axis(\"off\")\n",
        "        title_text = title or (captions[0] if captions else \"(no caption)\")\n",
        "        plt.title(title_text)\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"Image not decoded as PIL.Image; got type:\", type(image))\n",
        "        print(\"Row keys:\", list(row.keys()))\n",
        "\n",
        "\n",
        "def show_grid(rows: List[dict], cols: int = 2):\n",
        "    \"\"\"Display a grid of samples (images + first caption).\"\"\"\n",
        "    if not rows:\n",
        "        print(\"No rows to display.\")\n",
        "        return\n",
        "    rows_count = len(rows)\n",
        "    col_count = max(1, cols)\n",
        "    row_count = max(1, (rows_count + col_count - 1) // col_count)\n",
        "\n",
        "    plt.figure(figsize=(5 * col_count, 5 * row_count))\n",
        "    for i, row in enumerate(rows):\n",
        "        image = row.get(\"image\")\n",
        "        captions = row.get(\"caption\", [])\n",
        "        ax = plt.subplot(row_count, col_count, i + 1)\n",
        "        if isinstance(image, Image.Image):\n",
        "            ax.imshow(image)\n",
        "            ax.axis(\"off\")\n",
        "            ax.set_title(captions[0] if captions else \"(no caption)\")\n",
        "        else:\n",
        "            ax.text(0.5, 0.5, f\"Non-image type: {type(image)}\", ha=\"center\")\n",
        "            ax.axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Utilities: sample selection and keyword search\n",
        "import random\n",
        "\n",
        "random.seed(7)\n",
        "\n",
        "def get_n_samples(n: int = NUM_SAMPLES_DEFAULT):\n",
        "    if USE_STREAMING:\n",
        "        # For streaming, materialize the first n items\n",
        "        return [row for _, row in zip(range(n), ds)]\n",
        "    else:\n",
        "        indices = random.sample(range(len(ds)), k=min(n, len(ds)))\n",
        "        return [ds[i] for i in indices]\n",
        "\n",
        "\n",
        "def search_by_keyword(keyword: str, limit: int = 12):\n",
        "    \"\"\"Return up to `limit` rows where any caption contains the keyword (case-insensitive).\"\"\"\n",
        "    keyword_lower = keyword.lower()\n",
        "    results = []\n",
        "    if USE_STREAMING:\n",
        "        for row in ds:\n",
        "            captions = row.get(\"caption\", [])\n",
        "            if any(keyword_lower in c.lower() for c in captions):\n",
        "                results.append(row)\n",
        "                if len(results) >= limit:\n",
        "                    break\n",
        "    else:\n",
        "        for i in range(len(ds)):\n",
        "            row = ds[i]\n",
        "            captions = row.get(\"caption\", [])\n",
        "            if any(keyword_lower in c.lower() for c in captions):\n",
        "                results.append(row)\n",
        "                if len(results) >= limit:\n",
        "                    break\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quick test: show one random sample and a small grid\n",
        "samples = get_n_samples(4)\n",
        "\n",
        "# Show a single sample\n",
        "show_sample(samples[0])\n",
        "\n",
        "# Show a grid\n",
        "show_grid(samples, cols=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: save a few samples to disk\n",
        "from pathlib import Path\n",
        "\n",
        "def save_samples(rows: list, out_dir: str = \"./data/flickr30k-samples\"):\n",
        "    out_path = Path(out_dir)\n",
        "    out_path.mkdir(parents=True, exist_ok=True)\n",
        "    for idx, row in enumerate(rows):\n",
        "        image = row.get(\"image\")\n",
        "        filename = row.get(\"filename\") or f\"sample_{idx:04d}.jpg\"\n",
        "        if isinstance(image, Image.Image):\n",
        "            target = out_path / filename\n",
        "            # Ensure JPEG extension\n",
        "            if target.suffix.lower() not in {\".jpg\", \".jpeg\", \".png\"}:\n",
        "                target = target.with_suffix(\".jpg\")\n",
        "            image.save(target)\n",
        "            # Also save a tiny text file with the first caption\n",
        "            captions = row.get(\"caption\", [])\n",
        "            if captions:\n",
        "                (out_path / f\"{target.stem}.txt\").write_text(captions[0])\n",
        "        else:\n",
        "            print(f\"Skipping non-image sample at index {idx}.\")\n",
        "\n",
        "# Example: save 6 random samples\n",
        "samples_to_save = get_n_samples(6)\n",
        "save_samples(samples_to_save)\n",
        "print(\"Saved\", len(samples_to_save), \"samples.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
